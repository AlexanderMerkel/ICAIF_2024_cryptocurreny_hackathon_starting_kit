{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from os import path as pt\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from src.evaluation.summary import full_evaluation\n",
    "from src.utils import set_seed, save_obj, load_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8937, 24, 3])\n",
      "torch.Size([8937, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/ref_log_return.pkl\", \"rb\") as f:\n",
    "    loaded_array = pickle.load(f)\n",
    "train_log_return = torch.tensor(loaded_array)\n",
    "print(train_log_return.shape)\n",
    "\n",
    "with open(\"./data/ref_price.pkl\", \"rb\") as f:\n",
    "    loaded_array = pickle.load(f)\n",
    "train_init_price = torch.tensor(loaded_array)\n",
    "print(train_init_price.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative models for time series generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration dict\n",
    "config_dir = 'configs/config.yaml'\n",
    "with open(config_dir) as file:\n",
    "    config = ml_collections.ConfigDict(yaml.safe_load(file))\n",
    "    \n",
    "set_seed(config.seed)\n",
    "\n",
    "if (config.device ==\n",
    "        \"cuda\" and torch.cuda.is_available()):\n",
    "    config.update({\"device\": \"cuda:0\"}, allow_val_change=True)\n",
    "else:\n",
    "    config.update({\"device\": \"cpu\"}, allow_val_change=True)\n",
    "    \n",
    "class XYDataset(TensorDataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.shape = X.shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the data into training and validation set for the offline evaluation of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_idx = torch.randperm(train_log_return.shape[0])\n",
    "train_size = int(0.8*train_log_return.shape[0])\n",
    "\n",
    "cv_training_data = train_log_return[perm_idx[:train_size]].to(config.device).to(torch.float)\n",
    "cv_init_price = train_init_price[perm_idx[:train_size]].to(config.device).to(torch.float)\n",
    "cv_validation_data = train_log_return[perm_idx[train_size:]].to(config.device).to(torch.float)\n",
    "cv_val_init_price = train_init_price[perm_idx[train_size:]].to(config.device).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "training_set = TensorDataset(cv_init_price, cv_training_data)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    training_set,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "config.input_dim = cv_training_data[0][0].shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct a generator and a discriminator for this task. Both the generator and discriminator takes as input the time series. Then we have the training algorithm TailGANTrainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.baselines.networks.discriminators import Discriminator\n",
    "from src.baselines.networks.generators import Generator\n",
    "from src.baselines.TailGAN import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the generator, discriminator and the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(config)\n",
    "discriminator = Discriminator(config)\n",
    "trainer = TailGANTrainer(G=generator, D=discriminator,\n",
    "                    train_dl=train_dl, batch_size=config.batch_size, n_gradient_steps=config.steps,\n",
    "                    config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:52<00:00, 10.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "trainer.fit(config.device)\n",
    "# save_obj(trainer.G.state_dict(), './sample_submission_bundle/model_dict.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1600, 24, 3])\n"
     ]
    }
   ],
   "source": [
    "g_state_dict = load_obj('./sample_submission_bundle/model_dict.pkl')\n",
    "\n",
    "generator.load_state_dict(g_state_dict)\n",
    "\n",
    "generator.eval()\n",
    "\n",
    "eval_size = 1600\n",
    "\n",
    "with torch.no_grad():\n",
    "    fake_data = generator(batch_size = eval_size, device=config.device)\n",
    "    \n",
    "print(fake_data.shape)\n",
    "# Save the data\n",
    "# save_obj(fake_data, './sample_submission_bundle/fake_log_return.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the performance of our model by first generating the price process, apply the prespecified trading strategies and compare the resulting PnL process using the real and fake data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.67s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.68s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.63s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.65s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.87s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.87s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.88s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.86s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.72s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.83s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.64s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:12<00:00, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_mean 0.03359964117407799\n",
      "es_mean 0.07140812138095498\n",
      "max_drawback_mean 0.08072927594184875\n",
      "cumulative_pnl_mean 0.0835517537780106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation.strategies import log_return_to_price\n",
    "\n",
    "config_dir = 'src/evaluation/config.yaml'\n",
    "with open(config_dir) as file:\n",
    "    eval_config = ml_collections.ConfigDict(yaml.safe_load(file))\n",
    "\n",
    "fake_prices = log_return_to_price(fake_data[:eval_size], cv_val_init_price[:eval_size])\n",
    "cv_val = log_return_to_price(cv_validation_data[:eval_size], cv_val_init_price[:eval_size])\n",
    "\n",
    "all_positive = (fake_prices > 0).all()\n",
    "if not all_positive:\n",
    "    raise ValueError(\"Sanity Check Failed: Some fake prices are not positive.\")\n",
    "\n",
    "res_dict = {\"var_mean\" : 0., \"es_mean\": 0., \"max_drawback_mean\": 0., \"cumulative_pnl_mean\": 0.,}\n",
    "\n",
    "# Do final evaluation\n",
    "num_strat = 4\n",
    "\n",
    "for strat_name in ['equal_weight', 'mean_reversion', 'trend_following', 'vol_trading']:\n",
    "    subres_dict = full_evaluation(fake_prices, cv_val, eval_config, strat_name = strat_name)\n",
    "    for k in res_dict:\n",
    "        res_dict[k] += subres_dict[k] / num_strat\n",
    "        \n",
    "for k, v in res_dict.items():\n",
    "    print(k, v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
