{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from os import path as pt\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from src.evaluation.summary import full_evaluation\n",
    "from src.utils import set_seed, save_obj, load_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8937, 24, 3])\n",
      "torch.Size([8937, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/ref_log_return.pkl\", \"rb\") as f:\n",
    "    loaded_array = pickle.load(f)\n",
    "train_log_return = torch.tensor(loaded_array)\n",
    "print(train_log_return.shape)\n",
    "\n",
    "with open(\"./data/ref_price.pkl\", \"rb\") as f:\n",
    "    loaded_array = pickle.load(f)\n",
    "train_init_price = torch.tensor(loaded_array)\n",
    "print(train_init_price.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative models for time series generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration dict\n",
    "config_dir = 'configs/config.yaml'\n",
    "with open(config_dir) as file:\n",
    "    config = ml_collections.ConfigDict(yaml.safe_load(file))\n",
    "    \n",
    "set_seed(config.seed)\n",
    "\n",
    "if (config.device ==\n",
    "        \"cuda\" and torch.cuda.is_available()):\n",
    "    config.update({\"device\": \"cuda:0\"}, allow_val_change=True)\n",
    "else:\n",
    "    config.update({\"device\": \"cpu\"}, allow_val_change=True)\n",
    "    \n",
    "class XYDataset(TensorDataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.shape = X.shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have limited number of data, we choose to do cross-validation with 5-folds. We illustrate here just 1 division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_idx = torch.randperm(train_log_return.shape[0])\n",
    "train_size = int(0.8*train_log_return.shape[0])\n",
    "\n",
    "cv_training_data = train_log_return[perm_idx[:train_size]].to(config.device).to(torch.float)\n",
    "cv_init_price = train_init_price[perm_idx[:train_size]].to(config.device).to(torch.float)\n",
    "cv_validation_data = train_log_return[perm_idx[train_size:]].to(config.device).to(torch.float)\n",
    "cv_val_init_price = train_init_price[perm_idx[train_size:]].to(config.device).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "training_set = TensorDataset(cv_init_price, cv_training_data)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    training_set,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "config.input_dim = cv_training_data[0][0].shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct a generator and a discriminator for this task. Both the generator and discriminator takes as input the time series. Then we have the training algorithm TailGANTrainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.baselines.networks.discriminators import Discriminator\n",
    "from src.baselines.networks.generators import Generator\n",
    "from src.baselines.TailGAN import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the generator, discriminator and the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_out_dim = 1\n",
    "# return_seq = False\n",
    "\n",
    "generator = Generator(config)\n",
    "discriminator = Discriminator(config)\n",
    "trainer = TailGANTrainer(G=generator, D=discriminator,\n",
    "                    train_dl=train_dl, batch_size=config.batch_size, n_gradient_steps=config.steps,\n",
    "                    config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:51<00:00, 10.21s/it]\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "trainer.fit(config.device)\n",
    "# save_obj(trainer.G.state_dict(), './sample_submission_bundle/model_dict.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1800, 24, 3])\n"
     ]
    }
   ],
   "source": [
    "g_state_dict = load_obj('./sample_submission_bundle/model_dict.pkl')\n",
    "\n",
    "generator.load_state_dict(g_state_dict)\n",
    "\n",
    "generator.eval()\n",
    "\n",
    "eval_size = 1800\n",
    "\n",
    "with torch.no_grad():\n",
    "    fake_data = generator(batch_size = eval_size, device=config.device)\n",
    "    \n",
    "print(fake_data.shape)\n",
    "# Save the data\n",
    "# save_obj(fake_data, './sample_submission_bundle/fake_log_return.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic time series test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      " No metrics enabled in group = stylized_fact_scores\n",
      " No metrics enabled in group = implicit_scores\n",
      " No metrics enabled in group = sig_scores\n",
      " No metrics enabled in group = permutation_test\n",
      " No metrics enabled in group = distance_based_metrics\n",
      "---- evaluation metric = var in group = tail_scores ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- evaluation metric = es in group = tail_scores ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- evaluation metric = max_drawback in group = trading_strat_scores ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- evaluation metric = cumulative_pnl in group = trading_strat_scores ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_mean 0.032158513\n",
      "var_std 0.01205634\n",
      "es_mean 0.024387587\n",
      "es_std 0.003264293\n",
      "max_drawback_mean 0.03167302\n",
      "max_drawback_std 0.0011285115\n",
      "cumulative_pnl_mean 0.06434102\n",
      "cumulative_pnl_std 0.0017977617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation.strategies import log_return_to_price\n",
    "\n",
    "config_dir = 'src/evaluation/config.yaml'\n",
    "with open(config_dir) as file:\n",
    "    eval_config = ml_collections.ConfigDict(yaml.safe_load(file))\n",
    "\n",
    "fake_prices = log_return_to_price(fake_data, train_init_price[:eval_size, :, :])\n",
    "cv_val = log_return_to_price(cv_validation_data, cv_val_init_price)\n",
    "\n",
    "all_positive = (fake_prices > 0).all()\n",
    "if not all_positive:\n",
    "    raise ValueError(\"Sanity Check Failed: Some fake prices are not positive.\")\n",
    "\n",
    "res_dict_regular = full_evaluation(fake_prices, cv_val, eval_config)\n",
    "for k, v in res_dict_regular.items():\n",
    "    print(k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
